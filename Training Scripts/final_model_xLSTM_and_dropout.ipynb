{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roAnwK8RIa5i"
   },
   "source": [
    "# This is for the final model with xLSTM and dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqKCKeZ2IfR4",
    "outputId": "f5fdd7b3-a8c1-44a2-a650-871644c4bbcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xLSTM\n",
      "  Downloading xlstm-1.0.8-py3-none-any.whl.metadata (19 kB)\n",
      "Downloading xlstm-1.0.8-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xLSTM\n",
      "Successfully installed xLSTM-1.0.8\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ninja\n",
      "Successfully installed ninja-1.11.1.2\n",
      "Collecting xlstm\n",
      "  Downloading xlstm-1.0.8-py3-none-any.whl.metadata (19 kB)\n",
      "Downloading xlstm-1.0.8-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlstm\n",
      "  Attempting uninstall: xlstm\n",
      "    Found existing installation: xlstm 1.0.8\n",
      "    Uninstalling xlstm-1.0.8:\n",
      "      Successfully uninstalled xlstm-1.0.8\n",
      "Successfully installed xlstm-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install xLSTM\n",
    "!pip install ninja\n",
    "!pip install xlstm --force-reinstall --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVnpuIcuIAZm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KGPyJpvIGRI",
    "outputId": "4a6089a1-39b3-4318-a0ea-490176029534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXVBKbJt2F_t",
    "outputId": "7b503dc3-0954-4b80-bc04-bb389c21d199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCJpXUdiTvsb",
    "outputId": "0629f9a4-e382-41af-a6a8-9bbadf87faf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrMAPfa3IyMR"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters / Variability management\n",
    "DATALOADING_DATA_PATH = \"insert_file_path/all_tunes_cleaned_removed_whitespace.txt\"\n",
    "DATALOADING_VOCAB_PATH = \"insert_file_path/char_to_idx_truncated.json\"\n",
    "\n",
    "DATASET_SEQUENCE_LENGTH = 128\n",
    "LOADER_BATCH_SIZE = 126\n",
    "\n",
    "MODEL_EMBEDDING_DIM = 128 # Dimension of the embedding\n",
    "MODEL_HIDDEN_SIZE = 256 # LSTM layer size\n",
    "MODEL_LSTM_LAYERS = 4 # Number of LSTM layers\n",
    "MODEL_SAVE_PATH =   'insert_file_path/final_xLSTM_model.pt'\n",
    "\n",
    "TRAINING_EPOCHS = 15\n",
    "\n",
    "RESULTS_LOAD_PATH =  'insert_file_path/final_model_weights.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9di0aHVnQkqS"
   },
   "outputs": [],
   "source": [
    "with open(DATALOADING_DATA_PATH, \"r\") as f:\n",
    "  data = f.read()\n",
    "\n",
    "with open(DATALOADING_VOCAB_PATH) as f:\n",
    "    char_to_index = json.load(f)\n",
    "    index_to_char = {index: char for char, index in char_to_index.items()} # To transfer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_7YW_OeQ6Fc"
   },
   "outputs": [],
   "source": [
    "data_translated = [char_to_index[char] for char in data]\n",
    "data_translated = data_translated[:len(data_translated) // 250] # Truncate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgwWZWC8Qu6Y"
   },
   "outputs": [],
   "source": [
    "# Define the data set\n",
    "# WARNING: TAKES TRANSLATED DATA FORMAT\n",
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 X, # The data in TRANSLATED FORMAT\n",
    "                 sequence_len=1, # How much context does the model have?\n",
    "                 ):\n",
    "\n",
    "        self.X=torch.tensor(X, dtype=torch.long)\n",
    "        self.sequence_len=sequence_len\n",
    "\n",
    "    def __len__(self):\n",
    "      # Make room for a last sequence and its target, hence the 1 also\n",
    "        return len(self.X) - self.sequence_len - 1\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        X = self.X[idx:idx+self.sequence_len] # 1 x sequence_len\n",
    "        Ytarget = self.X[idx+self.sequence_len] # 1 x 1\n",
    "        return X, Ytarget.long() # For dimensions to match LSTM layer :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NpkYiRkQ2Dz"
   },
   "outputs": [],
   "source": [
    "dataset = MusicDataset(X=data_translated, sequence_len=DATASET_SEQUENCE_LENGTH)\n",
    "\n",
    "train_idx, test_idx = train_test_split(range(len(dataset)), test_size=.1, shuffle=False)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzk0ex2kRMxM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from xlstm import xLSTMBlockStack, xLSTMBlockStackConfig, mLSTMBlockConfig, mLSTMLayerConfig, sLSTMBlockConfig, sLSTMLayerConfig, FeedForwardConfig\n",
    "\n",
    "class SimpleModelWithxLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_size,\n",
    "                 context_length,\n",
    "                 num_blocks,\n",
    "                 slstm_at,\n",
    "                 dropout_prob = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "\n",
    "        # xLSTM configuration\n",
    "        self.xLSTM_cfg = xLSTMBlockStackConfig(\n",
    "            mlstm_block=mLSTMBlockConfig(\n",
    "                mlstm=mLSTMLayerConfig(\n",
    "                    conv1d_kernel_size=4,\n",
    "                    qkv_proj_blocksize=4,\n",
    "                    num_heads=4\n",
    "                )\n",
    "            ),\n",
    "            slstm_block=sLSTMBlockConfig(\n",
    "                slstm=sLSTMLayerConfig(\n",
    "                    backend=\"vanilla\",\n",
    "                    num_heads=4,\n",
    "                    conv1d_kernel_size=4,\n",
    "                    bias_init=\"powerlaw_blockdependent\",\n",
    "                ),\n",
    "                feedforward=FeedForwardConfig(\n",
    "                    proj_factor=1.3,\n",
    "                    act_fn=\"gelu\"\n",
    "                ),\n",
    "            ),\n",
    "            context_length=context_length,\n",
    "            num_blocks=num_blocks,\n",
    "            embedding_dim=embedding_dim,\n",
    "            slstm_at=slstm_at,\n",
    "        )\n",
    "\n",
    "        # Initialize xLSTM stack\n",
    "        self.xLSTM = xLSTMBlockStack(self.xLSTM_cfg)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.dropout_2 = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed the input\n",
    "        x = self.embedding(x)  # Shape: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        # Pass through the xLSTM stack\n",
    "        x = self.xLSTM(x)  # Shape: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        x = self.dropout_1(x)\n",
    "        # Take the last sequence step (e.g., for classification tasks)\n",
    "        x = x[:, -1, :]  # Shape: [batch_size, embedding_dim]\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)  # Shape: [batch_size, hidden_size]\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc2(x)  # Shape: [batch_size, vocab_size]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAZgGOeERNtA"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 95 #len(char_to_index)\n",
    "EMBEDDING_DIM = MODEL_EMBEDDING_DIM\n",
    "HIDDEN_SIZE = MODEL_HIDDEN_SIZE\n",
    "CONTEXT_LENGTH = DATASET_SEQUENCE_LENGTH\n",
    "NUM_BLOCKS = 4  # Number of xLSTM blocks\n",
    "SLSTM_AT = [1]  # Use sLSTM at specific layers\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleModelWithxLSTM(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    slstm_at=SLSTM_AT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "n_epochs = TRAINING_EPOCHS\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Because character classification task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hqw7DyCsR5Rn"
   },
   "outputs": [],
   "source": [
    "batch_size = LOADER_BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH3cuCo-SB0S",
    "outputId": "9679f2e3-acc9-4de6-9746-a58c507917b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch dim: torch.Size([126, 128])\n",
      "y batch dim: torch.Size([126])\n",
      "y_pred dim: torch.Size([126, 95])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.6346, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check loss function\n",
    "for x_batch, y_batch in train_loader:\n",
    "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "  break\n",
    "\n",
    "print(\"X batch dim:\", x_batch.shape)\n",
    "print(\"y batch dim:\", y_batch.shape)\n",
    "\n",
    "\n",
    "model_output = model(x_batch)\n",
    "print(\"y_pred dim:\", model_output.shape)\n",
    "\n",
    "loss_fn(model_output, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIKP7JmuTa36",
    "outputId": "78b79f56-ed23-46c1-e602-161db7773588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/148\n",
      "Accuracy 1.4016%\n",
      "Initial loss: 0.0363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TEST EVAL RUN\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_number, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_accuracy += (y_pred.argmax(dim=1) == y_batch).sum().item()\n",
    "\n",
    "        if batch_number % 1000 == 0:\n",
    "          print(f\"Batch {batch_number + 1}/{len(test_loader)}\")\n",
    "\n",
    "print(f\"Accuracy {test_accuracy / len(test_dataset) * 100:.4f}%\")\n",
    "print(f\"Initial loss: {test_loss / len(test_dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lrh3daDETgH6"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader):\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    losses = 0\n",
    "\n",
    "    for batch_number, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients (only if necessary)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses += loss.item()\n",
    "        correct_predictions += (y_pred.argmax(dim=1) == y_batch).sum().item()\n",
    "        total_samples += y_batch.size(0)\n",
    "\n",
    "        if batch_number % 1000 == 0:\n",
    "            print(f\"Batch {batch_number + 1}/{len(train_loader)}\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    train_loss.append(losses / len(train_loader))\n",
    "    train_accuracy.append(correct_predictions / total_samples)\n",
    "    print(f\"Train Loss: {train_loss[-1]:.4f}, Train Accuracy: {train_accuracy[-1] * 100:.2f}%\")\n",
    "\n",
    "\n",
    "def test(model, loss_fn, test_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    losses = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (x_batch, y_batch) in enumerate(test_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            losses += loss.item()\n",
    "            correct_predictions += (y_pred.argmax(dim=1) == y_batch).sum().item()\n",
    "            total_samples += y_batch.size(0)\n",
    "\n",
    "            if batch_number % 1000 == 0:\n",
    "                print(f\"Batch {batch_number + 1}/{len(test_loader)}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    test_loss.append(losses / len(test_loader))\n",
    "    test_accuracy.append(correct_predictions / total_samples)\n",
    "    print(f\"Test Loss: {test_loss[-1]:.4f}, Test Accuracy: {test_accuracy[-1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOTKeLx7Tj5y",
    "outputId": "90027b16-954b-47b0-cb16-b1063bb7e95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hidden size: 128, LSTM layers: 2\n",
      "Epoch 0/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 2.4630, Train Accuracy: 29.90%\n",
      "Batch 1/148\n",
      "Test Loss: 2.0714, Test Accuracy: 38.39%\n",
      "{'train_loss': [2.4630188775367077], 'test_loss': [2.0713664309398547], 'train_accuracy': [0.29897245560435365], 'test_accuracy': [0.38386767627946944]}\n",
      "Epoch 1/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 2.0201, Train Accuracy: 40.02%\n",
      "Batch 1/148\n",
      "Test Loss: 1.9397, Test Accuracy: 41.37%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063], 'test_loss': [2.0713664309398547, 1.9396705861027177], 'train_accuracy': [0.29897245560435365, 0.40024107313347335], 'test_accuracy': [0.38386767627946944, 0.4136727350840449]}\n",
      "Epoch 2/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.8858, Train Accuracy: 43.60%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8826, Test Accuracy: 43.70%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932]}\n",
      "Epoch 3/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.8048, Train Accuracy: 45.72%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8376, Test Accuracy: 44.57%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099]}\n",
      "Epoch 4/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.7447, Train Accuracy: 47.44%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8357, Test Accuracy: 45.58%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057]}\n",
      "Epoch 5/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.6866, Train Accuracy: 49.25%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7935, Test Accuracy: 47.05%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433]}\n",
      "Epoch 6/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.6402, Train Accuracy: 50.81%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7705, Test Accuracy: 47.35%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344]}\n",
      "Epoch 7/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.5965, Train Accuracy: 52.10%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7873, Test Accuracy: 47.66%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232]}\n",
      "Epoch 8/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.5596, Train Accuracy: 53.19%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7913, Test Accuracy: 48.72%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795]}\n",
      "Epoch 9/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.5221, Train Accuracy: 54.30%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7702, Test Accuracy: 48.64%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777]}\n",
      "Epoch 10/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.4865, Train Accuracy: 55.31%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7887, Test Accuracy: 49.01%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397, 1.4865364350831929], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265, 1.7886663530323956], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418, 0.5530778594615238], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777, 0.49014553461146015]}\n",
      "Epoch 11/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.4542, Train Accuracy: 56.17%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8002, Test Accuracy: 48.87%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397, 1.4865364350831929, 1.4541630946452415], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265, 1.7886663530323956, 1.800193741514876], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418, 0.5530778594615238, 0.5617004009929348], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777, 0.49014553461146015, 0.488749261586381]}\n",
      "Epoch 12/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.4258, Train Accuracy: 57.00%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8040, Test Accuracy: 49.05%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397, 1.4865364350831929, 1.4541630946452415, 1.4257767446770155], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265, 1.7886663530323956, 1.800193741514876, 1.8040012942778099], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418, 0.5530778594615238, 0.5617004009929348, 0.5699529788046591], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777, 0.49014553461146015, 0.488749261586381, 0.49052145427205845]}\n",
      "Epoch 13/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.3964, Train Accuracy: 57.71%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8473, Test Accuracy: 49.15%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397, 1.4865364350831929, 1.4541630946452415, 1.4257767446770155, 1.3963783591605057], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265, 1.7886663530323956, 1.800193741514876, 1.8040012942778099, 1.847295017661275], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418, 0.5530778594615238, 0.5617004009929348, 0.5699529788046591, 0.5770658296734772], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777, 0.49014553461146015, 0.488749261586381, 0.49052145427205845, 0.4914881048278825]}\n",
      "Epoch 14/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.3687, Train Accuracy: 58.60%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8357, Test Accuracy: 49.15%\n",
      "{'train_loss': [2.4630188775367077, 2.0201199234741063, 1.8858480137331337, 1.804839479484386, 1.744679681794434, 1.6866456750279346, 1.640183573285052, 1.596468358896085, 1.559588435804996, 1.5220569978523397, 1.4865364350831929, 1.4541630946452415, 1.4257767446770155, 1.3963783591605057, 1.3687252725182755], 'test_loss': [2.0713664309398547, 1.9396705861027177, 1.8826304939953056, 1.8375678730977547, 1.8356745323619328, 1.7934907553969204, 1.7705151398439665, 1.787291711246645, 1.791328755584923, 1.7701915349509265, 1.7886663530323956, 1.800193741514876, 1.8040012942778099, 1.847295017661275, 1.835670675780322], 'train_accuracy': [0.29897245560435365, 0.40024107313347335, 0.43603804659156004, 0.45717371586786326, 0.4743770288333015, 0.49252911972503344, 0.5080914645789574, 0.5210222932976896, 0.53187655146076, 0.5429993316784418, 0.5530778594615238, 0.5617004009929348, 0.5699529788046591, 0.5770658296734772, 0.5860165648271911], 'test_accuracy': [0.38386767627946944, 0.4136727350840449, 0.4370334568497932, 0.4457333118522099, 0.4558294398797057, 0.47054400945169433, 0.47349766392782344, 0.4766124268299232, 0.48724558294398795, 0.4863863380054777, 0.49014553461146015, 0.488749261586381, 0.49052145427205845, 0.4914881048278825, 0.4915418076365394]}\n",
      "Model hidden size: 256, LSTM layers: 4\n",
      "Epoch 0/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 2.2936, Train Accuracy: 33.97%\n",
      "Batch 1/148\n",
      "Test Loss: 1.9399, Test Accuracy: 41.23%\n",
      "{'train_loss': [2.2935572403163325], 'test_loss': [1.9398759313531824], 'train_accuracy': [0.3396803990834447], 'test_accuracy': [0.4123301648676226]}\n",
      "Epoch 1/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.8707, Train Accuracy: 43.56%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8355, Test Accuracy: 44.49%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936], 'test_loss': [1.9398759313531824, 1.8354797677413837], 'train_accuracy': [0.3396803990834447, 0.4355666412067978], 'test_accuracy': [0.4123301648676226, 0.4449277697223565]}\n",
      "Epoch 2/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.7437, Train Accuracy: 47.33%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7609, Test Accuracy: 46.25%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173]}\n",
      "Epoch 3/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.6541, Train Accuracy: 50.17%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7310, Test Accuracy: 48.04%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567]}\n",
      "Epoch 4/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.5821, Train Accuracy: 52.43%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7250, Test Accuracy: 48.52%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915]}\n",
      "Epoch 5/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.5213, Train Accuracy: 54.31%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7105, Test Accuracy: 48.96%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124]}\n",
      "Epoch 6/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.4595, Train Accuracy: 56.19%\n",
      "Batch 1/148\n",
      "Test Loss: 1.6783, Test Accuracy: 50.12%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232]}\n",
      "Epoch 7/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.4076, Train Accuracy: 57.75%\n",
      "Batch 1/148\n",
      "Test Loss: 1.6978, Test Accuracy: 49.83%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651]}\n",
      "Epoch 8/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.3554, Train Accuracy: 59.18%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7040, Test Accuracy: 50.27%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375, 1.3554064383818456], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463, 1.704020843312547], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555, 0.5917927725797212], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651, 0.5027119918371731]}\n",
      "Epoch 9/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.3054, Train Accuracy: 60.67%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7297, Test Accuracy: 50.35%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375, 1.3554064383818456, 1.3054200604300494], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463, 1.704020843312547, 1.7296725704863265], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555, 0.5917927725797212, 0.6066509929348863], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651, 0.5027119918371731, 0.5034638311583696]}\n",
      "Epoch 10/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.2549, Train Accuracy: 62.02%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7690, Test Accuracy: 50.19%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375, 1.3554064383818456, 1.3054200604300494, 1.2548660692373315], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463, 1.704020843312547, 1.7296725704863265, 1.7689923313823905], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555, 0.5917927725797212, 0.6066509929348863, 0.6201785373305327], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651, 0.5027119918371731, 0.5034638311583696, 0.5019064497073197]}\n",
      "Epoch 11/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.2123, Train Accuracy: 63.56%\n",
      "Batch 1/148\n",
      "Test Loss: 1.7913, Test Accuracy: 50.64%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375, 1.3554064383818456, 1.3054200604300494, 1.2548660692373315, 1.2122866527018559], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463, 1.704020843312547, 1.7296725704863265, 1.7689923313823905, 1.7912824274720371], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555, 0.5917927725797212, 0.6066509929348863, 0.6201785373305327, 0.6356036375787665], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651, 0.5027119918371731, 0.5034638311583696, 0.5019064497073197, 0.5064174856344987]}\n",
      "Epoch 12/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n",
      "Train Loss: 1.1688, Train Accuracy: 64.73%\n",
      "Batch 1/148\n",
      "Test Loss: 1.8197, Test Accuracy: 50.24%\n",
      "{'train_loss': [2.2935572403163325, 1.8706902208227936, 1.7436941115145035, 1.6541267366538273, 1.5820897210369784, 1.5213243294084637, 1.4595015727873586, 1.407590210930375, 1.3554064383818456, 1.3054200604300494, 1.2548660692373315, 1.2122866527018559, 1.1688232716539586], 'test_loss': [1.9398759313531824, 1.8354797677413837, 1.7609284093251099, 1.7309885782164496, 1.7250224666015521, 1.7104982604851593, 1.6782862552114435, 1.6977566230941463, 1.704020843312547, 1.7296725704863265, 1.7689923313823905, 1.7912824274720371, 1.8196587739764034], 'train_accuracy': [0.3396803990834447, 0.4355666412067978, 0.47330294061485584, 0.5017125739927439, 0.5242803608936414, 0.5431425434409013, 0.56187344853924, 0.5774954649608555, 0.5917927725797212, 0.6066509929348863, 0.6201785373305327, 0.6356036375787665, 0.6473350677869009], 'test_accuracy': [0.4123301648676226, 0.4449277697223565, 0.4625422909618173, 0.48037162343590567, 0.48515117340636915, 0.48960850652489124, 0.5011546103861232, 0.498254658718651, 0.5027119918371731, 0.5034638311583696, 0.5019064497073197, 0.5064174856344987, 0.5024434777938886]}\n",
      "Epoch 13/15\n",
      "Batch 1/1331\n",
      "Batch 1001/1331\n"
     ]
    }
   ],
   "source": [
    "# patience = 2\n",
    "# best_loss = float('inf')\n",
    "# epochs_without_improvement = 0\n",
    "\n",
    "model_hidden_size_list = [128, 256]\n",
    "lstm_layers_list = [2, 4]\n",
    "\n",
    "model_dict_dropout = dict()\n",
    "\n",
    "for model_hidden_size, lstm_layers in zip(model_hidden_size_list, lstm_layers_list):\n",
    "    print(f\"Model hidden size: {model_hidden_size}, LSTM layers: {lstm_layers}\")\n",
    "    model = SimpleModelWithxLSTM(\n",
    "          vocab_size=VOCAB_SIZE,\n",
    "          embedding_dim=EMBEDDING_DIM,\n",
    "          hidden_size=model_hidden_size,\n",
    "          context_length=CONTEXT_LENGTH,\n",
    "          num_blocks=lstm_layers,\n",
    "          slstm_at=SLSTM_AT\n",
    "      ).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss() # Because character classification task\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    model_results = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "\n",
    "        # Train and test the model\n",
    "        train(model, optimizer, loss_fn, train_loader)\n",
    "        test(model, loss_fn, test_loader)\n",
    "\n",
    "        # Save metrics for this epoch\n",
    "        model_results['train_loss'].append(train_loss[-1])\n",
    "        model_results['test_loss'].append(test_loss[-1])\n",
    "        model_results['train_accuracy'].append(train_accuracy[-1])\n",
    "        model_results['test_accuracy'].append(test_accuracy[-1])\n",
    "        print(model_results)\n",
    "\n",
    "    # Store the results for this model configuration in the dictionary\n",
    "    model_dict_dropout[(model_hidden_size, lstm_layers)] = model_results\n",
    "\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#   if epoch % 1 == 0:\n",
    "#     print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "#   train(model, optimizer, loss_fn, train_loader)\n",
    "#   test(model, loss_fn, test_loader)\n",
    "\n",
    "#   if test_loss[-1] < best_loss:\n",
    "#     best_loss = test_loss[-1]\n",
    "#     epochs_without_improvement = 0\n",
    "\n",
    "#   else:\n",
    "#     epochs_without_improvement += 1\n",
    "#   if epochs_without_improvement >= patience:\n",
    "#     print(\"Early stopping triggered.\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUncWsrPalIq"
   },
   "outputs": [],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJd0HRV3l0Dh"
   },
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sCpo4qHl2Q1"
   },
   "outputs": [],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDGKx4Q6l6yg",
    "outputId": "bbb0a342-a675-45ec-dcd1-2e9f953223e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bfugms_ymNUy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label='train')\n",
    "plt.plot(range(len(test_loss)), test_loss, label='test')\n",
    "plt.title(\"Loss plot of train and test loss function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0lin_VImSNf"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_accuracy)), train_accuracy, label='train')\n",
    "plt.plot(range(len(test_accuracy)), test_accuracy, label='test')\n",
    "plt.title(\"Loss plot of train and test accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTl3VBRfM3OV"
   },
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LR0Xl39lQp9N"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim=128,\n",
    "                 hidden_size=256,\n",
    "                 context_length=128,\n",
    "                 num_blocks=7,\n",
    "                 slstm_at=[1],\n",
    "                 batch_size=32, # hyperparams from here\n",
    "                 dropout_prob=0.5,\n",
    "                 learning_rate=0.001,\n",
    "                 epochs=1):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.context_length = context_length\n",
    "        self.num_blocks = num_blocks\n",
    "        self.slstm_at = slstm_at\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.long)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        \"\"\"\n",
    "        setting the classes totally fucks the vram, it tries to allocate\n",
    "        80gb no matter the batchsize. I have no clue why\n",
    "        \"\"\"\n",
    "        self.classes_ = list(set(y.numpy()))\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(X, y)), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model = SimpleModelWithxLSTM(\n",
    "            vocab_size=self.vocab_size,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            context_length=self.context_length,\n",
    "            num_blocks=self.num_blocks,\n",
    "            slstm_at=self.slstm_at).to(self.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            train(self.model, optimizer, loss_fn, train_loader)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.long).to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "          y_pred = self.model(X)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return torch.argmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    def score(self, X, y):\n",
    "\n",
    "        X_tensor = torch.LongTensor(X)\n",
    "        y_tensor = torch.LongTensor(y)\n",
    "        test_loader = torch.utils.data.DataLoader(list(zip(X_tensor, y_tensor)), batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Evaluate model\n",
    "        test(self.model, nn.CrossEntropyLoss(), test_loader)\n",
    "\n",
    "        # Return accuracy\n",
    "        return test_accuracy[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwU22wyP6j2z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dataloader_to_arrays(dataloader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        X.append(x_batch.numpy())\n",
    "        y.append(y_batch.numpy())\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8sK7wNyYucJ",
    "outputId": "a4b728cb-f873-4f89-e7f4-eec4d0112d1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/435\n",
      "Train Loss: 2.8851, Train Accuracy: 21.26%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8845, Train Accuracy: 21.85%\n",
      "Batch 1/435\n",
      "Train Loss: 2.9021, Train Accuracy: 21.21%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6499, Train Accuracy: 9.42%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6698, Train Accuracy: 9.19%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6314, Train Accuracy: 9.07%\n",
      "Batch 1/435\n",
      "Train Loss: 4.5375, Train Accuracy: 1.61%\n",
      "Batch 1/435\n",
      "Train Loss: 4.4984, Train Accuracy: 2.78%\n",
      "Batch 1/435\n",
      "Train Loss: 4.5068, Train Accuracy: 2.13%\n",
      "Batch 1/435\n",
      "Train Loss: 2.9025, Train Accuracy: 21.20%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8895, Train Accuracy: 21.54%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8842, Train Accuracy: 21.32%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6495, Train Accuracy: 9.38%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6388, Train Accuracy: 9.40%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6577, Train Accuracy: 9.38%\n",
      "Batch 1/435\n",
      "Train Loss: 4.4726, Train Accuracy: 2.69%\n",
      "Batch 1/435\n",
      "Train Loss: 4.5240, Train Accuracy: 2.05%\n",
      "Batch 1/435\n",
      "Train Loss: 4.5128, Train Accuracy: 2.13%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8977, Train Accuracy: 20.85%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8959, Train Accuracy: 21.90%\n",
      "Batch 1/435\n",
      "Train Loss: 2.8731, Train Accuracy: 22.53%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6747, Train Accuracy: 9.89%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6692, Train Accuracy: 8.79%\n",
      "Batch 1/435\n",
      "Train Loss: 3.6588, Train Accuracy: 8.97%\n",
      "Batch 1/435\n",
      "Train Loss: 4.5404, Train Accuracy: 1.85%\n",
      "Batch 1/435\n",
      "Train Loss: 4.4838, Train Accuracy: 2.73%\n",
      "Batch 1/435\n",
      "Train Loss: 4.4962, Train Accuracy: 1.73%\n",
      "Batch 1/652\n",
      "Train Loss: 2.7251, Train Accuracy: 25.46%\n",
      "Best Parameters: {'dropout_prob': 0.7, 'learning_rate': 0.001}\n",
      "Best CV Score: 0.32535334540748523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'dropout_prob': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "pytorch_clf = PyTorchClassifier(vocab_size=VOCAB_SIZE)\n",
    "\n",
    "X_train, y_train = dataloader_to_arrays(train_loader)\n",
    "X_test, y_test = dataloader_to_arrays(test_loader)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pytorch_clf, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5phQFwQf5MsN"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J5oAOC21toR"
   },
   "outputs": [],
   "source": [
    "x = [\"din\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AZhXPC11wDI"
   },
   "outputs": [],
   "source": [
    "torch.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "6wBGOPb-CV0H",
    "outputId": "4f434683-de55-464e-fdf0-7dde67d0d09c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\\n  warnings.warn(\\nBatch 1/435\\nTrain Loss: 2.8851, Train Accuracy: 21.26%\\nBatch 1/435\\nTrain Loss: 2.8845, Train Accuracy: 21.85%\\nBatch 1/435\\nTrain Loss: 2.9021, Train Accuracy: 21.21%\\nBatch 1/435\\nTrain Loss: 3.6499, Train Accuracy: 9.42%\\nBatch 1/435\\nTrain Loss: 3.6698, Train Accuracy: 9.19%\\nBatch 1/435\\nTrain Loss: 3.6314, Train Accuracy: 9.07%\\nBatch 1/435\\nTrain Loss: 4.5375, Train Accuracy: 1.61%\\nBatch 1/435\\nTrain Loss: 4.4984, Train Accuracy: 2.78%\\nBatch 1/435\\nTrain Loss: 4.5068, Train Accuracy: 2.13%\\nBatch 1/435\\nTrain Loss: 2.9025, Train Accuracy: 21.20%\\nBatch 1/435\\nTrain Loss: 2.8895, Train Accuracy: 21.54%\\nBatch 1/435\\nTrain Loss: 2.8842, Train Accuracy: 21.32%\\nBatch 1/435\\nTrain Loss: 3.6495, Train Accuracy: 9.38%\\nBatch 1/435\\nTrain Loss: 3.6388, Train Accuracy: 9.40%\\nBatch 1/435\\nTrain Loss: 3.6577, Train Accuracy: 9.38%\\nBatch 1/435\\nTrain Loss: 4.4726, Train Accuracy: 2.69%\\nBatch 1/435\\nTrain Loss: 4.5240, Train Accuracy: 2.05%\\nBatch 1/435\\nTrain Loss: 4.5128, Train Accuracy: 2.13%\\nBatch 1/435\\nTrain Loss: 2.8977, Train Accuracy: 20.85%\\nBatch 1/435\\nTrain Loss: 2.8959, Train Accuracy: 21.90%\\nBatch 1/435\\nTrain Loss: 2.8731, Train Accuracy: 22.53%\\nBatch 1/435\\nTrain Loss: 3.6747, Train Accuracy: 9.89%\\nBatch 1/435\\nTrain Loss: 3.6692, Train Accuracy: 8.79%\\nBatch 1/435\\nTrain Loss: 3.6588, Train Accuracy: 8.97%\\nBatch 1/435\\nTrain Loss: 4.5404, Train Accuracy: 1.85%\\nBatch 1/435\\nTrain Loss: 4.4838, Train Accuracy: 2.73%\\nBatch 1/435\\nTrain Loss: 4.4962, Train Accuracy: 1.73%\\nBatch 1/652\\nTrain Loss: 2.7251, Train Accuracy: 25.46%\\nBest Parameters: {'dropout_prob': 0.7, 'learning_rate': 0.001}\\nBest CV Score: 0.32535334540748523\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
    "  warnings.warn(\n",
    "Batch 1/435\n",
    "Train Loss: 2.8851, Train Accuracy: 21.26%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8845, Train Accuracy: 21.85%\n",
    "Batch 1/435\n",
    "Train Loss: 2.9021, Train Accuracy: 21.21%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6499, Train Accuracy: 9.42%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6698, Train Accuracy: 9.19%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6314, Train Accuracy: 9.07%\n",
    "Batch 1/435\n",
    "Train Loss: 4.5375, Train Accuracy: 1.61%\n",
    "Batch 1/435\n",
    "Train Loss: 4.4984, Train Accuracy: 2.78%\n",
    "Batch 1/435\n",
    "Train Loss: 4.5068, Train Accuracy: 2.13%\n",
    "Batch 1/435\n",
    "Train Loss: 2.9025, Train Accuracy: 21.20%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8895, Train Accuracy: 21.54%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8842, Train Accuracy: 21.32%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6495, Train Accuracy: 9.38%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6388, Train Accuracy: 9.40%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6577, Train Accuracy: 9.38%\n",
    "Batch 1/435\n",
    "Train Loss: 4.4726, Train Accuracy: 2.69%\n",
    "Batch 1/435\n",
    "Train Loss: 4.5240, Train Accuracy: 2.05%\n",
    "Batch 1/435\n",
    "Train Loss: 4.5128, Train Accuracy: 2.13%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8977, Train Accuracy: 20.85%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8959, Train Accuracy: 21.90%\n",
    "Batch 1/435\n",
    "Train Loss: 2.8731, Train Accuracy: 22.53%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6747, Train Accuracy: 9.89%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6692, Train Accuracy: 8.79%\n",
    "Batch 1/435\n",
    "Train Loss: 3.6588, Train Accuracy: 8.97%\n",
    "Batch 1/435\n",
    "Train Loss: 4.5404, Train Accuracy: 1.85%\n",
    "Batch 1/435\n",
    "Train Loss: 4.4838, Train Accuracy: 2.73%\n",
    "Batch 1/435\n",
    "Train Loss: 4.4962, Train Accuracy: 1.73%\n",
    "Batch 1/652\n",
    "Train Loss: 2.7251, Train Accuracy: 25.46%\n",
    "Best Parameters: {'dropout_prob': 0.7, 'learning_rate': 0.001}\n",
    "Best CV Score: 0.32535334540748523\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "P6CPcDxjRUql",
    "outputId": "15b00953-0d59-43df-ce43-d3f89a5c558e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "best_scores = np.array(results['mean_test_score'])\n",
    "\n",
    "# Reshape the best scores into a 2D grid for plotting (based on the length of parameter lists)\n",
    "score_matrix = best_scores.reshape(len(param_grid['learning_rate']), len(param_grid['dropout_prob']))\n",
    "\n",
    "# Create a heatmap of the grid search results\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(score_matrix,\n",
    "            annot=True,\n",
    "            cmap='YlGnBu',\n",
    "            xticklabels=param_grid['learning_rate'],\n",
    "            yticklabels=param_grid['dropout_prob'])\n",
    "\n",
    "plt.xlabel('Dropout Probability')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Grid Search Heatmap: Best Accuracy Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Rpw147mSW5P"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgklSQ8iSmn-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from xlstm import xLSTMBlockStack, xLSTMBlockStackConfig, mLSTMBlockConfig, mLSTMLayerConfig, sLSTMBlockConfig, sLSTMLayerConfig, FeedForwardConfig\n",
    "\n",
    "class SimpleModelWithxLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_size,\n",
    "                 context_length,\n",
    "                 num_blocks,\n",
    "                 slstm_at,\n",
    "                 dropout_prob = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "\n",
    "        # xLSTM configuration\n",
    "        self.xLSTM_cfg = xLSTMBlockStackConfig(\n",
    "            mlstm_block=mLSTMBlockConfig(\n",
    "                mlstm=mLSTMLayerConfig(\n",
    "                    conv1d_kernel_size=4,\n",
    "                    qkv_proj_blocksize=4,\n",
    "                    num_heads=4\n",
    "                )\n",
    "            ),\n",
    "            slstm_block=sLSTMBlockConfig(\n",
    "                slstm=sLSTMLayerConfig(\n",
    "                    backend=\"vanilla\",\n",
    "                    num_heads=4,\n",
    "                    conv1d_kernel_size=4,\n",
    "                    bias_init=\"powerlaw_blockdependent\",\n",
    "                ),\n",
    "                feedforward=FeedForwardConfig(\n",
    "                    proj_factor=1.3,\n",
    "                    act_fn=\"gelu\"\n",
    "                ),\n",
    "            ),\n",
    "            context_length=context_length,\n",
    "            num_blocks=num_blocks,\n",
    "            embedding_dim=embedding_dim,\n",
    "            slstm_at=slstm_at,\n",
    "        )\n",
    "\n",
    "        # Initialize xLSTM stack\n",
    "        self.xLSTM = xLSTMBlockStack(self.xLSTM_cfg)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.dropout_2 = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed the input\n",
    "        x = self.embedding(x)  # Shape: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        # Pass through the xLSTM stack\n",
    "        x = self.xLSTM(x)  # Shape: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        x = self.dropout_1(x)\n",
    "        # Take the last sequence step (e.g., for classification tasks)\n",
    "        x = x[:, -1, :]  # Shape: [batch_size, embedding_dim]\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)  # Shape: [batch_size, hidden_size]\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc2(x)  # Shape: [batch_size, vocab_size]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJkDv0H-_5_y",
    "outputId": "27e86d88-a931-459d-dab0-0eed12e7dea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvguBhTB_vN-"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 95\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_SIZE = 128\n",
    "CONTEXT_LENGTH = 128\n",
    "NUM_BLOCKS = 2  # Number of xLSTM blocks\n",
    "SLSTM_AT = [1]  # Use sLSTM at specific layers\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleModelWithxLSTM(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    slstm_at=SLSTM_AT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "n_epochs = TRAINING_EPOCHS\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Because character classification task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m--mcgrh_y3y",
    "outputId": "9ae00191-059a-473b-8fbb-8e19c13b86cb"
   },
   "outputs": [],
   "source": [
    "model_weights = \"insert_file_path\"\n",
    "model.load_state_dict(torch.load(model_weights))\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdRXK7Pt_Qpd"
   },
   "outputs": [],
   "source": [
    "# Define the data set\n",
    "# WARNING: TAKES TRANSLATED DATA FORMAT\n",
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 X, # The data in TRANSLATED FORMAT\n",
    "                 sequence_len=1, # How much context does the model have?\n",
    "                 ):\n",
    "\n",
    "        self.X=torch.tensor(X, dtype=torch.long)\n",
    "        self.sequence_len=sequence_len\n",
    "\n",
    "    def __len__(self):\n",
    "      # Make room for a last sequence and its target, hence the 1 also\n",
    "        return len(self.X) - self.sequence_len - 1\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        X = self.X[idx:idx+self.sequence_len] # 1 x sequence_len\n",
    "        Ytarget = self.X[idx+self.sequence_len] # 1 x 1\n",
    "        return X, Ytarget.long() # For dimensions to match LSTM layer :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bk_nMIeD-s0a",
    "outputId": "4a8714b4-c6b9-4cf9-fce6-9cb793e5591b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ1c0D5Z_FC6"
   },
   "outputs": [],
   "source": [
    "model_weights = \"/insert_file_path/big_model_lstm_save.pt\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
